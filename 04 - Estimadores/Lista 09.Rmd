---
title: "Lista 09"
author: "Matheus Cougias"
date: "28/02/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Leitura dos dados:**
Baseado nos resultados da lista anterior, a regressão será aplicada diretamente no modelo onde foi aplicado o logaritmo aos dados, devido sua maior capacidade tanto de compreensão dos dados (R² múltiplo) quanto de sua capacidade preditiva (R² preditivo).
```{r leituraDados, results=FALSE}
dados <- read.delim("boston_corrected.txt")
dados <- subset(dados, select = -c(OBS., TOWN, TOWN., TRACT, LON, LAT, CMEDV))
dt <- data.frame(MEDV=log(dados$MEDV),
                    CRIM=log(dados$CRIM),
                    ZN=log(dados$ZN+1),
                    INDUS=log(dados$INDUS),
                    CHAS=log(dados$CHAS+1),
                    NOX=log(dados$NOX),
                    RM=log(dados$RM),
                    AGE=log(dados$AGE),
                    DIS=log(dados$DIS),
                    RAD=log(dados$RAD),
                    TAX=log(dados$TAX),
                    PTRATIO=log(dados$PTRATIO),
                    B=log(dados$B),
                    LSTAT=log(dados$LSTAT))
```

**Modelo de regressão linear múltipla (com logaritmo):**
Através do modelo de regressão linear múltipla onde o logaritmo foi aplicado, alguns dados podem ser levantados:
- Possui um R² múltiplo de 76,96% e R² ajustado de 76,35%;
- Possu um R² preditivo de 75,42197%;
- As variáveis CRIM e NOX se destacam com os maiores valores de VIF, 86,61% e 83,33% respectivamente.
```{r}
require(car)
modelo <- lm(MEDV ~ CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO + B + LSTAT, data=dt)
summary(modelo)
1 - 1/vif(modelo)

Y <- as.matrix(dt$MEDV)
SQT <- sum((Y - mean(Y))^2)

X <- model.matrix(modelo)

H <- X%*%solve(t(X)%*%X)%*%t(X)
res <- Y - H%*%Y
aux <- 1 - diag(H)
res_del <- res/(1-diag(H))
SQRes <- sum(res_del^2)
(R2pred <- 1 - SQRes/SQT)
```

**Melhorando O R² preditivo:**
Na busca por um melhor resultado de R² preditivo, aplica-se um ajuste do Estimador de Ridge Regression, gerando um R² preditivo de 75,45716%.
```{r ridgeRegression}
beta <- solve(t(X)%*%X)%*%t(X)%*%Y
Identidade <- diag(c(0,rep(1, nrow(beta)-1)))

R2predFun <- function(lmbd)
{
  Identidade <- diag(c(0,rep(1, nrow(beta)-1)))
  beta <- solve(t(X)%*%X + lmbd*Identidade)%*%t(X)%*%Y
  H <- X%*%solve(t(X)%*%X + lmbd*Identidade)%*%t(X)
  res <- Y - H%*%Y
  aux <- 1 - diag(H)
  res_del <- res/(1-diag(H))
  SQRes <- sum(res_del^2)
  R2pred <- 1 - SQRes/SQT
  return(R2pred)
}

saida <- optimize(R2predFun, lower=0.001, upper=1.2, maximum = TRUE)
lambda <- saida$maximum
(saida$objective)
beta <- solve(t(X)%*%X + lambda*Identidade)%*%t(X)%*%Y
```

**Análise dos resultados:**
Ao compararmos os resutados, houve uma leve melhora entre o modelo inicial e o modelo de regressão onde o Estimador de Ridge foi apicado, cerca de 0,03519%. Uma ideia de que talvez o estimador não tenha afetado tão positivamente o modelo de regressão pode ser dada por, talvez, pela sua sensibilidade em relação aos outliers (ou pontos discrepantes) da base de dados. Para melhorar esse resultado, seria interessante realizar um  tratamento prévio dos dados, de modo que o modelo se adeque melhor às informações. 
